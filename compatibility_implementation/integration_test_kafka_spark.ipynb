{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d079bf96-c574-4a7e-9a32-356c3701f71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark[kafka,sql] in d:\\programming\\python\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in d:\\programming\\python\\lib\\site-packages (from pyspark[kafka,sql]) (0.10.9.7)\n",
      "Requirement already satisfied: pandas>=1.0.5 in d:\\programming\\python\\lib\\site-packages (from pyspark[kafka,sql]) (2.2.3)\n",
      "Collecting pyarrow>=4.0.0 (from pyspark[kafka,sql])\n",
      "  Downloading pyarrow-18.1.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting numpy<2,>=1.15 (from pyspark[kafka,sql])\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.8/15.8 MB 5.0 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.3/15.8 MB 3.8 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 2.1/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.6/15.8 MB 3.0 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.1/15.8 MB 3.0 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 3.7/15.8 MB 2.9 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 4.2/15.8 MB 2.8 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 4.7/15.8 MB 2.8 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 5.2/15.8 MB 2.7 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 5.8/15.8 MB 2.7 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 6.3/15.8 MB 2.7 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 7.1/15.8 MB 2.7 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 7.6/15.8 MB 2.7 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 8.1/15.8 MB 2.8 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 8.7/15.8 MB 2.7 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 9.2/15.8 MB 2.7 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 9.7/15.8 MB 2.7 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 10.2/15.8 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 11.0/15.8 MB 2.7 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 11.5/15.8 MB 2.7 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 12.3/15.8 MB 2.7 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 13.1/15.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 13.9/15.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 13.9/15.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 14.4/15.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 14.4/15.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.7/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.7/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.7/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.7/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.7/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.7/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.9/15.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.9/15.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.9/15.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.9/15.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.9/15.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.9/15.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.9/15.8 MB 2.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.2/15.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.5/15.8 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.5/15.8 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.8/15.8 MB 1.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programming\\python\\lib\\site-packages (from pandas>=1.0.5->pyspark[kafka,sql]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programming\\python\\lib\\site-packages (from pandas>=1.0.5->pyspark[kafka,sql]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\programming\\python\\lib\\site-packages (from pandas>=1.0.5->pyspark[kafka,sql]) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programming\\python\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->pyspark[kafka,sql]) (1.16.0)\n",
      "Downloading pyarrow-18.1.0-cp313-cp313-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/25.1 MB 1.6 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.8/25.1 MB 1.5 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.0/25.1 MB 1.6 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 1.3/25.1 MB 1.5 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 1.8/25.1 MB 1.5 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 2.1/25.1 MB 1.5 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 2.4/25.1 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.9/25.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 3.4/25.1 MB 1.7 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 3.9/25.1 MB 1.8 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 4.5/25.1 MB 1.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 5.0/25.1 MB 1.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 5.5/25.1 MB 1.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 5.8/25.1 MB 1.9 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.3/25.1 MB 1.9 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 1.9 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 7.1/25.1 MB 1.9 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 7.3/25.1 MB 1.9 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 7.9/25.1 MB 1.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 8.4/25.1 MB 1.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 9.2/25.1 MB 2.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 9.7/25.1 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.2/25.1 MB 2.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 10.7/25.1 MB 2.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 11.0/25.1 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 11.5/25.1 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 12.1/25.1 MB 2.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 12.3/25.1 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 13.1/25.1 MB 2.1 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.4/25.1 MB 2.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 14.2/25.1 MB 2.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.7/25.1 MB 2.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 15.2/25.1 MB 2.1 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.0/25.1 MB 2.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.8/25.1 MB 2.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.3/25.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.8/25.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.4/25.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 18.9/25.1 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.7/25.1 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.2/25.1 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 20.7/25.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.5/25.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.3/25.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.1/25.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/25.1 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.9/25.1 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 2.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (pyproject.toml): started\n",
      "  Building wheel for numpy (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-win_amd64.whl size=9857950 sha256=dce337c23f690c3e0cad826d5fbbea2e8badfce63e27addb20e561c869e7802e\n",
      "  Stored in directory: c:\\users\\jainil\\appdata\\local\\pip\\cache\\wheels\\8b\\2d\\9f\\b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "Successfully built numpy\n",
      "Installing collected packages: pyarrow, numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed numpy-1.26.4 pyarrow-18.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pyspark 3.5.3 does not provide the extra 'kafka'\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\programming\\python\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\programming\\python\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# !pip install pyspark[sql,kafka]\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "048b8217-d185-4234-a246-d613028d6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"spark_kafka_test\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl.disable.cache\", \"true\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ae5b665-81cb-47ee-8e39-cd39bed594f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ayushjainil:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark_kafka_test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e5e1221d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d06e287-81b4-4540-8a73-2cb8e689b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_bootstrap_server = 'localhost:9092'\n",
    "kafka_topic = \"test_topic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8983a3d0-3687-4860-8b74-13df23e9539c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_topic'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_bootstrap_server\n",
    "kafka_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5dbf1e7-6477-40f5-ab24-c78f575f5a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadStream\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka.bootstrap.servers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkafka_bootstrap_server\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubscribe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkafka_topic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\programming\\python\\Lib\\site-packages\\pyspark\\sql\\streaming\\readwriter.py:304\u001b[0m, in \u001b[0;36mDataStreamReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(path))\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\programming\\python\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mD:\\programming\\python\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide."
     ]
    }
   ],
   "source": [
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap_server) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf289b31-b8e0-48b5-97e1-6f86cf3506b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
